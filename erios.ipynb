{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiIsXuv9piqRZPMYGeaD4M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c4c68213ccf426ea0d253cb9c25aa8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85024eefa3614cec802e2a1a08402f6d",
              "IPY_MODEL_4d7e889e283e4224be8b524775dd115b",
              "IPY_MODEL_ce79c3a1e31c4bdb9f65037cf824801d"
            ],
            "layout": "IPY_MODEL_980f5ba3b87a40b99fce0a549849cafd"
          }
        },
        "85024eefa3614cec802e2a1a08402f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deb63d6b62c441d5affbd2f0dd83e017",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c8e717392108454592eb8827f3d4c2fa",
            "value": "Batches:‚Äá100%"
          }
        },
        "4d7e889e283e4224be8b524775dd115b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a01d4d1d6bf746889b60f3f167b2f2c9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e528542d7214707bcfa9b422d9a3f8a",
            "value": 1
          }
        },
        "ce79c3a1e31c4bdb9f65037cf824801d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24712bcffa2941eba0203bc33a3e1104",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_86166f5627be48f9b8f39848dad66d84",
            "value": "‚Äá1/1‚Äá[00:01&lt;00:00,‚Äá‚Äá1.33s/it]"
          }
        },
        "980f5ba3b87a40b99fce0a549849cafd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb63d6b62c441d5affbd2f0dd83e017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e717392108454592eb8827f3d4c2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a01d4d1d6bf746889b60f3f167b2f2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e528542d7214707bcfa9b422d9a3f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24712bcffa2941eba0203bc33a3e1104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86166f5627be48f9b8f39848dad66d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JC-Delmas/Erios_test/blob/main/erios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation des d√©pendances (CPU)\n",
        "!pip install -qU \\\n",
        "  llama-cpp-python \\\n",
        "  sentence-transformers \\\n",
        "  faiss-cpu \\\n",
        "  python-docx \\\n",
        "  tqdm"
      ],
      "metadata": {
        "id": "v5wThAxrjDbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T√©l√©chargement du mod√®le & import du .docx (augmentation du prompt par RAG)\n",
        "# Mod√®le quantifi√© (3,5 Go)\n",
        "!wget -q https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_S.gguf -O /content/mistral.gguf\n",
        "\n",
        "from google.colab import files\n",
        "import pathlib\n",
        "\n",
        "# Import du fichier qui augmente le prompt (RAG)\n",
        "uploaded = files.upload()\n",
        "DOC_PATH = pathlib.Path(next(iter(uploaded)))   # on garde le chemin\n",
        "print(\"Document charg√© :\", DOC_PATH)"
      ],
      "metadata": {
        "id": "dii1_VwPAypF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "3466df2e-7064-4149-9801-9a83beae66b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-36dd167e-048d-4215-b370-89394e987e5c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-36dd167e-048d-4215-b370-89394e987e5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PAC_synthese_avec_texte_figure.docx to PAC_synthese_avec_texte_figure.docx\n",
            "Document charg√© : PAC_synthese_avec_texte_figure.docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, docx, faiss, numpy as np, textwrap, sys, types, time, re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from llama_cpp import Llama\n",
        "\n",
        "MODEL  = \"/content/mistral.gguf\" # on choisi arbitrairement un mod√®le llm open source fran√ßais\n",
        "DOC    = str(DOC_PATH)      #  document renseign√© dans la cellule 2\n",
        "TOP_K  = 4                  # 4 passages pour raccourcir le prompt pour optimiser la vitesse de r√©ponse du llm\n",
        "N_CTX  = 2048\n",
        "THREAD = os.cpu_count()\n",
        "\n",
        "# --- correctif fileno() uniquement pour Colab\n",
        "for s,fd in ((sys.stdout,1),(sys.stderr,2)):\n",
        "    s.fileno = types.MethodType(lambda self,fd=fd: fd, s)\n",
        "\n",
        "# 1) Extraction du texte\n",
        "paras=[p.text.strip() for p in docx.Document(DOC).paragraphs if p.text.strip()]\n",
        "chunks,buff=[], \"\"\n",
        "for p in paras:\n",
        "    buff += \" \" + p\n",
        "    if len(buff.split()) > 40:\n",
        "        chunks.append(buff.strip()); buff=\"\"\n",
        "if buff: chunks.append(buff.strip())\n",
        "print(f\"‚úÖ {len(chunks)} passages extraits.\") # on quantifie les passages\n",
        "\n",
        "# 2) Embeddings + index (pour fonctionnement CPU)\n",
        "enc = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "emb = enc.encode(chunks, normalize_embeddings=True, show_progress_bar=True)\n",
        "index = faiss.IndexFlatIP(emb.shape[1]); index.add(emb.astype(\"float32\"))\n",
        "print(\"‚úÖ Index vectoriel pr√™t.\")\n",
        "\n",
        "# 3) Chargement du mod√®le CPU\n",
        "print(\"Chargement du LLM, cela peut prendre quelques instants ...\")\n",
        "llm = Llama(model_path=MODEL, n_ctx=N_CTX, n_threads=THREAD, n_batch=256, verbose=False)\n",
        "print(f\"‚úÖ Mod√®le charg√© ({THREAD} threads, contexte {N_CTX})\")\n",
        "\n",
        "SYSTEM = (\"Tu es un assistant m√©dical. R√©ponds en fran√ßais de fa√ßon concise, \"\n",
        "          \"sans jamais poser de nouvelle question. \"\n",
        "          \"Cite tes sources sous la forme [source N] et termine ta r√©ponse \"\n",
        "          \"par le symbole <FIN>.\")\n",
        "\n",
        "def repondre(question: str):\n",
        "    global enc, index, chunks\n",
        "    # recherche vectorielle\n",
        "    q_vec = enc.encode([question], normalize_embeddings=True)\n",
        "    _, idxs = index.search(q_vec.astype(\"float32\"), TOP_K)\n",
        "    idxs = idxs[0].tolist()\n",
        "\n",
        "    # filtrage simple par mots-cl√©s extraits de la question\n",
        "    mots = [w.lower().strip(\".,;:!?\") for w in question.split() if len(w) > 4] # on garde les mots de plus de quatre lettres, utile pour le nom des m√©dicaments\n",
        "    nombres = re.findall(r\"\\d+\", question)     # r√©cup√®re tous les nombres de la question\n",
        "    idxs = [i for i in idxs\n",
        "            if any(m in chunks[i].lower() for m in mots) or      # contient un mot clef\n",
        "               any(n in chunks[i] for n in nombres)]              # ou contient un nombre\n",
        "\n",
        "    # construction du contexte\n",
        "    contexte = \"\\n\\n\".join(f\"(source {i}) {chunks[i]}\" for i in idxs)\n",
        "    prompt = (f\"{SYSTEM}\\n\\nContexte :\\n{contexte}\\n\\n\"\n",
        "              f\"Q : {question}\\nA : \")\n",
        "\n",
        "    print(\"\\n‚ñ∂Ô∏è g√©n√©ration :\", end=\" \", flush=True); t0 = time.time()\n",
        "\n",
        "    # streaming token-par-token\n",
        "    out = []\n",
        "    for chunk in llm(prompt,\n",
        "                     stream=True,\n",
        "                     max_tokens=256,\n",
        "                     temperature=0.1,\n",
        "                     stop=[\"<FIN>\"]):\n",
        "        tok = chunk[\"choices\"][0][\"text\"]\n",
        "        if tok:\n",
        "            print(tok, end=\"\", flush=True)\n",
        "            out.append(tok)     # m√©morise le texte\n",
        "\n",
        "    print(f\"\\n‚è± {time.time()-t0:.1f} s\")\n",
        "\n",
        "    # on r√©cup√®re les num√©ros r√©ellement cit√©s\n",
        "    answer_text = \"\".join(out)\n",
        "    cited = {int(n) for n in re.findall(r\"\\[source (\\d+)\", answer_text)} #regex qui permet de r√©cup√©rer plusieurs sources ex. [source 2, 9]\n",
        "\n",
        "    print(\"\\n---\\nSources :\")\n",
        "    for i in sorted(cited):                          # on n‚Äôaffiche QUE ceux cit√©s\n",
        "        if i < len(chunks):                          # s√©curit√© indice\n",
        "            extrait = textwrap.shorten(chunks[i], width=180, placeholder=\"‚Ä¶\")\n",
        "            print(f\"[source {i}] ¬´ {extrait} ¬ª\")\n",
        "    print()\n",
        "\n",
        "# Boucle interactive\n",
        "while True:\n",
        "    try:\n",
        "        q = input(\"\\n‚ùì Posez votre question m√©dicale (Entr√©e pour quitter) : \").strip()\n",
        "        if not q:\n",
        "          print(\"Au revoir.\")\n",
        "          break\n",
        "        repondre(q)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interruption volontaire du programme.\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c4c68213ccf426ea0d253cb9c25aa8b",
            "85024eefa3614cec802e2a1a08402f6d",
            "4d7e889e283e4224be8b524775dd115b",
            "ce79c3a1e31c4bdb9f65037cf824801d",
            "980f5ba3b87a40b99fce0a549849cafd",
            "deb63d6b62c441d5affbd2f0dd83e017",
            "c8e717392108454592eb8827f3d4c2fa",
            "a01d4d1d6bf746889b60f3f167b2f2c9",
            "1e528542d7214707bcfa9b422d9a3f8a",
            "24712bcffa2941eba0203bc33a3e1104",
            "86166f5627be48f9b8f39848dad66d84"
          ]
        },
        "id": "e2OJn6iNlN1T",
        "outputId": "f32ae48e-9bc0-4a2d-926f-f1a08726119e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 15 passages extraits.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c4c68213ccf426ea0d253cb9c25aa8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Index vectoriel pr√™t.\n",
            "Chargement du LLM, cela peut prendre quelques instants ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mod√®le charg√© (2 threads, contexte 2048)\n",
            "\n",
            "‚ùì Pose ta question (Entr√©e pour quitter) : Quelles sont les trois indications d‚Äôun scanner thoracique low-dose selon la synth√®se ?\n",
            "\n",
            "‚ñ∂Ô∏è g√©n√©ration : 1. Doute diagnostique, 2. Pas d'am√©lioration apr√®s 72 heures, 3. Facteur de risque de cancer (> 50 ans et > 20 PA) apr√®s 2 mois. [source 9, 0] \n",
            "‚è± 139.9 s\n",
            "\n",
            "---\n",
            "Sources :\n",
            "[source 9] ¬´ ‚Ä¢ R√©√©valuation √† J4 ; d√©croissance progressive ‚Ä¢ Dur√©e totale 8‚Äì14 jours 9. Examens compl√©mentaires ‚Ä¢ 1√®re intention : Radiographie thoracique ou √©chographie pulmonaire ‚Ä¢ TDM‚Ä¶ ¬ª\n",
            "\n",
            "\n",
            "‚ùì Pose ta question (Entr√©e pour quitter) : Quels examens microbiologiques doivent √™tre imp√©rativement r√©alis√©s avant la premi√®re injection d‚Äôantibiotique chez une PAC grave hospitalis√©e ?\n",
            "\n",
            "‚ñ∂Ô∏è g√©n√©ration :  Chez une PAC grave hospitalis√©e, il est imp√©ratif de r√©aliser un pr√©l√®vement de sang pour une culture sanguine avant la premi√®re injection d'antibiotique [source 6]. \n",
            "‚è± 116.8 s\n",
            "\n",
            "---\n",
            "Sources :\n",
            "[source 6] ¬´ ‚Ä¢ Ceftriaxone 1‚Äì2 g/j IV ‚Ä¢ ou Cefotaxime 1‚Äì2 g IV toutes 8 h üîπ Suspicion germe atypique (sujet jeune) ou allergie Œ≤‚Äëlactamines : ‚Ä¢ Azithromycine 500 mg/j ‚Ä¢ ou L√©vofloxacine 500‚Ä¶ ¬ª\n",
            "\n",
            "\n",
            "‚ùì Pose ta question (Entr√©e pour quitter) : Quelle dur√©e totale d‚Äôantibioth√©rapie doit-on prescrire chez un patient atteint de PAC non compliqu√©e si les crit√®res de stabilit√© clinique ne sont atteints qu‚Äôentre J3 et J5 ?\n",
            "\n",
            "‚ñ∂Ô∏è g√©n√©ration : 5 jours [source 1 et 7] \n",
            "‚è± 137.2 s\n",
            "\n",
            "---\n",
            "Sources :\n",
            "[source 1] ¬´ 2. Points cl√©s ‚Ä¢ Crit√®res de stabilit√© : apyrexie, stabilit√© h√©modynamique, pouls ‚â§ 100/min, FR ‚â§ 24/min, SpO‚ÇÇ ‚â• 90 % (AA). ‚Ä¢ Si crit√®res atteints √† J3 ‚Üí 3 jours d'antibiotiques ;‚Ä¶ ¬ª\n",
            "\n",
            "\n",
            "‚ùì Pose ta question (Entr√©e pour quitter) : Cite les deux crit√®res majeurs qui, √† eux seuls, classent une pneumonie aigu√´ communautaire dans la cat√©gorie ¬´ grave ¬ª.\n",
            "\n",
            "‚ñ∂Ô∏è g√©n√©ration : 1. Choc septique n√©cessitant des amines, 2. D√©tresse respiratoire n√©cessitant ventilation m√©canique \n",
            "‚è± 171.9 s\n",
            "\n",
            "---\n",
            "Sources :\n",
            "\n",
            "\n",
            "‚ùì Pose ta question (Entr√©e pour quitter) : Donnez trois exemples de comorbidit√©s ou facteurs de risque qui font choisir une antibioth√©rapie probabiliste √©largie (tableau 2).\n",
            "\n",
            "‚ñ∂Ô∏è g√©n√©ration : 1. Immunod√©pression [source 5]\n",
            "2. N√©oplasie active [source 5]\n",
            "3. BPCO s√©v√®re ou insuffisance respiratoire chronique [source 13] \n",
            "‚è± 119.3 s\n",
            "\n",
            "---\n",
            "Sources :\n",
            "[source 5] ¬´ ‚Ä¢ N√©oplasie active ‚Ä¢ Immunod√©pression ‚Ä¢ BPCO s√©v√®re ou insuffisance respiratoire chronique 6. Antibioth√©rapie probabiliste (adulte hospitalis√©) üîπ PAC non grave, sans comorbidit√© :‚Ä¶ ¬ª\n",
            "[source 13] ¬´ - vie en institution. D√©cision d‚Äôorientation : - √Çge < 65 ans sans ou avec un seul facteur de risque ‚Üí prise en charge ambulatoire - √Çge < 65 ans et ‚â• 2 facteurs de risque ‚Üí‚Ä¶ ¬ª\n",
            "\n",
            "\n",
            "‚ùì Pose ta question (Entr√©e pour quitter) : \n",
            "Au revoir.\n"
          ]
        }
      ]
    }
  ]
}